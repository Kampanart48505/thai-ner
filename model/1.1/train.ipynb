{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6306\n",
      "6306\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# เรียกใช้งานโมดูล\n",
    "file_name=\"data\"\n",
    "import codecs\n",
    "from pythainlp.tokenize import word_tokenize\n",
    "#import deepcut\n",
    "from pythainlp.tag import pos_tag\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import glob\n",
    "import nltk\n",
    "import re\n",
    "# thai cut\n",
    "thaicut=\"newmm\"\n",
    "from sklearn_crfsuite import scorers,metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_validate,train_test_split\n",
    "import sklearn_crfsuite\n",
    "from pythainlp.corpus.common import thai_stopwords\n",
    "stopwords = list(thai_stopwords())\n",
    "#จัดการประโยคซ้ำ\n",
    "data_not=[]\n",
    "def Unique(p):\n",
    " text=re.sub(\"<[^>]*>\",\"\",p)\n",
    " text=re.sub(\"\\[(.*?)\\]\",\"\",text)\n",
    " text=re.sub(\"\\[\\/(.*?)\\]\",\"\",text)\n",
    " if text not in data_not:\n",
    "  data_not.append(text)\n",
    "  return True\n",
    " else:\n",
    "  return False\n",
    "# เตรียมตัวตัด tag ด้วย re\n",
    "pattern = r'\\[(.*?)\\](.*?)\\[\\/(.*?)\\]'\n",
    "tokenizer = RegexpTokenizer(pattern) # ใช้ nltk.tokenize.RegexpTokenizer เพื่อตัด [TIME]8.00[/TIME] ให้เป็น ('TIME','ไง','TIME')\n",
    "# จัดการกับ tag ที่ไม่ได้ tag\n",
    "def toolner_to_tag(text):\n",
    " text=text.strip().replace(\"FACILITY\",\"LOCATION\").replace(\"[AGO]\",\"\").replace(\"[/AGO]\",\"\").replace(\"[T]\",\"\").replace(\"[/T]\",\"\")\n",
    " text=re.sub(\"<[^>]*>\",\"\",text)\n",
    " text=re.sub(\"(\\[\\/(.*?)\\])\",\"\\\\1***\",text)#.replace('(\\[(.*?)\\])','***\\\\1')# text.replace('>','>***') # ตัดการกับพวกไม่มี tag word\n",
    " text=re.sub(\"(\\[\\w+\\])\",\"***\\\\1\",text)\n",
    " text2=[]\n",
    " for i in text.split('***'):\n",
    "  if \"[\" in i:\n",
    "   text2.append(i)\n",
    "  else:\n",
    "   text2.append(\"[word]\"+i+\"[/word]\")\n",
    " text=\"\".join(text2)#re.sub(\"[word][/word]\",\"\",\"\".join(text2))\n",
    " return text.replace(\"[word][/word]\",\"\")\n",
    "# แปลง text ให้เป็น conll2002\n",
    "def text2conll2002(text,pos=True):\n",
    "    \"\"\"\n",
    "    ใช้แปลงข้อความให้กลายเป็น conll2002\n",
    "    \"\"\"\n",
    "    text=toolner_to_tag(text)\n",
    "    text=text.replace(\"''\",'\"')\n",
    "    text=text.replace(\"’\",'\"').replace(\"‘\",'\"')#.replace('\"',\"\")\n",
    "    tag=tokenizer.tokenize(text)\n",
    "    j=0\n",
    "    conll2002=\"\"\n",
    "    for tagopen,text,tagclose in tag:\n",
    "        word_cut=word_tokenize(text,engine=thaicut) # ใช้ตัวตัดคำ newmm\n",
    "        i=0\n",
    "        txt5=\"\"\n",
    "        while i<len(word_cut):\n",
    "            if word_cut[i]==\"''\" or word_cut[i]=='\"':pass\n",
    "            elif i==0 and tagopen!='word':\n",
    "                txt5+=word_cut[i]\n",
    "                txt5+='\\t'+'B-'+tagopen\n",
    "            elif tagopen!='word':\n",
    "                txt5+=word_cut[i]\n",
    "                txt5+='\\t'+'I-'+tagopen\n",
    "            else:\n",
    "                txt5+=word_cut[i]\n",
    "                txt5+='\\t'+'O'\n",
    "            txt5+='\\n'\n",
    "            #j+=1\n",
    "            i+=1\n",
    "        conll2002+=txt5\n",
    "    if pos==False:\n",
    "        return conll2002\n",
    "    return postag(conll2002)\n",
    "# ใช้สำหรับกำกับ pos tag เพื่อใช้กับ NER\n",
    "# print(text2conll2002(t,pos=False))\n",
    "def postag(text):\n",
    "    listtxt=[i for i in text.split('\\n') if i!='']\n",
    "    list_word=[]\n",
    "    for data in listtxt:\n",
    "        list_word.append(data.split('\\t')[0])\n",
    "    #print(text)\n",
    "    list_word=pos_tag(list_word,engine=\"perceptron\", corpus=\"orchid_ud\")\n",
    "    text=\"\"\n",
    "    i=0\n",
    "    for data in listtxt:\n",
    "        text+=data.split('\\t')[0]+'\\t'+list_word[i][1]+'\\t'+data.split('\\t')[1]+'\\n'\n",
    "        i+=1\n",
    "    return text\n",
    "# เขียนไฟล์ข้อมูล conll2002\n",
    "def write_conll2002(file_name,data):\n",
    "    \"\"\"\n",
    "    ใช้สำหรับเขียนไฟล์\n",
    "    \"\"\"\n",
    "    with codecs.open(file_name, \"w\", \"utf-8-sig\") as temp:\n",
    "        temp.write(data)\n",
    "    return True\n",
    "# อ่านข้อมูลจากไฟล์\n",
    "def get_data(fileopen):\n",
    "\t\"\"\"\n",
    "    สำหรับใช้อ่านทั้งหมดทั้งในไฟล์ทีละรรทัดออกมาเป็น list\n",
    "    \"\"\"\n",
    "\twith codecs.open(fileopen, 'r',encoding='utf-8-sig') as f:\n",
    "\t\tlines = f.read().splitlines()\n",
    "\treturn [a for a in lines if Unique(a)] # เอาไม่ซ้ำกัน\n",
    "\n",
    "def alldata(lists):\n",
    "    text=\"\"\n",
    "    for data in lists:\n",
    "        text+=text2conll2002(data)\n",
    "        text+='\\n'\n",
    "    return text\n",
    "\n",
    "def alldata_list(lists):\n",
    "    data_all=[]\n",
    "    for data in lists:\n",
    "        data_num=[]\n",
    "        try:\n",
    "            txt=text2conll2002(data,pos=True).split('\\n')\n",
    "            for d in txt:\n",
    "                tt=d.split('\\t')\n",
    "                if d!=\"\":\n",
    "                    if len(tt)==3:\n",
    "                        data_num.append((tt[0],tt[1],tt[2]))\n",
    "                    else:\n",
    "                        data_num.append((tt[0],tt[1]))\n",
    "            #print(data_num)\n",
    "            data_all.append(data_num)\n",
    "        except:\n",
    "            print(data)\n",
    "    #print(data_all)\n",
    "    return data_all\n",
    "\n",
    "def alldata_list_str(lists):\n",
    "\tstring=\"\"\n",
    "\tfor data in lists:\n",
    "\t\tstring1=\"\"\n",
    "\t\tfor j in data:\n",
    "\t\t\tstring1+=j[0]+\"\t\"+j[1]+\"\t\"+j[2]+\"\\n\"\n",
    "\t\tstring1+=\"\\n\"\n",
    "\t\tstring+=string1\n",
    "\treturn string\n",
    "\n",
    "def get_data_tag(listd):\n",
    "\tlist_all=[]\n",
    "\tc=[]\n",
    "\tfor i in listd:\n",
    "\t\tif i !='':\n",
    "\t\t\tc.append((i.split(\"\\t\")[0],i.split(\"\\t\")[1],i.split(\"\\t\")[2]))\n",
    "\t\telse:\n",
    "\t\t\tlist_all.append(c)\n",
    "\t\t\tc=[]\n",
    "\treturn list_all\n",
    "def getall(lista):\n",
    "    ll=[]\n",
    "    for i in lista:\n",
    "        o=True\n",
    "        for j in ll:\n",
    "            if re.sub(\"\\[(.*?)\\]\",\"\",i)==re.sub(\"\\[(.*?)\\]\",\"\",j):\n",
    "                o=False\n",
    "                break\n",
    "        if o==True:\n",
    "            ll.append(i)\n",
    "    return ll\n",
    "\n",
    "data1=getall(get_data(file_name+\".txt\"))\n",
    "print(len(data1))\n",
    "'''\n",
    "import dill\n",
    "with open('datatrain.data', 'rb') as file:\n",
    " datatofile = dill.load(file)\n",
    "'''\n",
    "#del datatofile[0]\n",
    "datatofile=alldata_list(data1)\n",
    "tt=[]\n",
    "#datatofile.reverse()\n",
    "import random\n",
    "#random.shuffle(datatofile)\n",
    "print(len(datatofile))\n",
    "#training_samples = datatofile[:int(len(datatofile) * 0.8)]\n",
    "#test_samples = datatofile[int(len(datatofile) * 0.8):]\n",
    "'''training_samples = datatofile[:2822]\n",
    "test_samples = datatofile[2822:]'''\n",
    "#print(test_samples[0])\n",
    "#tag=TrainChunker(training_samples,test_samples) # Train\n",
    "\n",
    "#run(training_samples,test_samples)\n",
    "with open(file_name+\"-pos.conll\",\"w\") as f:\n",
    "    i=0\n",
    "    while i<len(datatofile):\n",
    "        for j in datatofile[i]:\n",
    "            f.write(j[0]+\"\\t\"+j[1]+\"\\t\"+j[2]+\"\\n\")\n",
    "        if i+1<len(datatofile):\n",
    "            f.write(\"\\n\")\n",
    "        i+=1\n",
    "\n",
    "with open(file_name+\".conll\",\"w\") as f:\n",
    "    i=0\n",
    "    while i<len(datatofile):\n",
    "        for j in datatofile[i]:\n",
    "            f.write(j[0]+\"\\t\"+j[2]+\"\\n\")\n",
    "        if i+1<len(datatofile):\n",
    "            f.write(\"\\n\")\n",
    "        i+=1\n",
    "\n",
    "\n",
    "def isThai(chr):\n",
    " cVal = ord(chr)\n",
    " if(cVal >= 3584 and cVal <= 3711):\n",
    "  return True\n",
    " return False\n",
    "def isThaiWord(word):\n",
    " t=True\n",
    " for i in word:\n",
    "  l=isThai(i)\n",
    "  if l!=True and i!='.':\n",
    "   t=False\n",
    "   break\n",
    " return t\n",
    "\n",
    "def is_stopword(word):\n",
    "    return word in stopwords\n",
    "def is_s(word):\n",
    "    if word == \" \" or word ==\"\\t\" or word==\"\":\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def lennum(word,num):\n",
    "    if len(word)==num:\n",
    "        return True\n",
    "    return False\n",
    "def doc2features(doc, i):\n",
    "    word = doc[i][0]\n",
    "    postag = doc[i][1]\n",
    "    # Features from current word\n",
    "    features={\n",
    "        'word.word': word,\n",
    "        'word.stopword': is_stopword(word),\n",
    "        'word.isthai':isThaiWord(word),\n",
    "        'word.isspace':word.isspace(),\n",
    "        'postag':postag,\n",
    "        'word.isdigit()': word.isdigit()\n",
    "    }\n",
    "    if word.isdigit() and len(word)==5:\n",
    "        features['word.islen5']=True\n",
    "    if i > 0:\n",
    "        prevword = doc[i-1][0]\n",
    "        postag1 = doc[i-1][1]\n",
    "        features['word.prevword'] = prevword\n",
    "        features['word.previsspace']=prevword.isspace()\n",
    "        features['word.previsthai']=isThaiWord(prevword)\n",
    "        features['word.prevstopword']=is_stopword(prevword)\n",
    "        features['word.prepostag'] = postag1\n",
    "        features['word.prevwordisdigit'] = prevword.isdigit()\n",
    "    else:\n",
    "        features['BOS'] = True # Special \"Beginning of Sequence\" tag\n",
    "    # Features from next word\n",
    "    if i < len(doc)-1:\n",
    "        nextword = doc[i+1][0]\n",
    "        postag1 = doc[i+1][1]\n",
    "        features['word.nextword'] = nextword\n",
    "        features['word.nextisspace']=nextword.isspace()\n",
    "        features['word.nextpostag'] = postag1\n",
    "        features['word.nextisthai']=isThaiWord(nextword)\n",
    "        features['word.nextstopword']=is_stopword(nextword)\n",
    "        features['word.nextwordisdigit'] = nextword.isdigit()\n",
    "    else:\n",
    "        features['EOS'] = True # Special \"End of Sequence\" tag\n",
    "    return features\n",
    "\n",
    "def extract_features(doc):\n",
    "    return [doc2features(doc, i) for i in range(len(doc))]\n",
    "\n",
    "def get_labels(doc):\n",
    "    return [tag for (token,postag,tag) in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word.word': ' ', 'word.stopword': False, 'word.isthai': False, 'word.isspace': True, 'postag': 'PUNCT', 'word.isdigit()': False, 'BOS': True, 'word.nextword': '[', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': '[', 'word.stopword': False, 'word.isthai': False, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': ' ', 'word.previsspace': True, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'PUNCT', 'word.prevwordisdigit': False, 'word.nextword': 'ORGANIZATION', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ORGANIZATION', 'word.stopword': False, 'word.isthai': False, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': '[', 'word.previsspace': False, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': ']', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': ']', 'word.stopword': False, 'word.isthai': False, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'ORGANIZATION', 'word.previsspace': False, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ไมโครซอฟท์', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ไมโครซอฟท์', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': ']', 'word.previsspace': False, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ทดสอบ', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ทดสอบ', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': 'ไมโครซอฟท์', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ฟีเจอร์', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ฟีเจอร์', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'ทดสอบ', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'word.nextword': 'ใหม่', 'word.nextisspace': False, 'word.nextpostag': 'ADJ', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'ใหม่', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'ADJ', 'word.isdigit()': False, 'word.prevword': 'ฟีเจอร์', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': ' ', 'word.nextisspace': True, 'word.nextpostag': 'PUNCT', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': ' ', 'word.stopword': False, 'word.isthai': False, 'word.isspace': True, 'postag': 'PUNCT', 'word.isdigit()': False, 'word.prevword': 'ใหม่', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'ADJ', 'word.prevwordisdigit': False, 'word.nextword': 'เป็น', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'เป็น', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': ' ', 'word.previsspace': True, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'PUNCT', 'word.prevwordisdigit': False, 'word.nextword': 'ช่องทาง', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ช่องทาง', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'เป็น', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'word.nextword': 'จัดการ', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'จัดการ', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': 'ช่องทาง', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ข้อมูล', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ข้อมูล', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'จัดการ', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'word.nextword': 'ส่วนตัว', 'word.nextisspace': False, 'word.nextpostag': 'ADJ', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ส่วนตัว', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'ADJ', 'word.isdigit()': False, 'word.prevword': 'ข้อมูล', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ที่', 'word.nextisspace': False, 'word.nextpostag': 'SCONJ', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'ที่', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'SCONJ', 'word.isdigit()': False, 'word.prevword': 'ส่วนตัว', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'ADJ', 'word.prevwordisdigit': False, 'word.nextword': 'บริษัท', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'บริษัท', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'ที่', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'SCONJ', 'word.prevwordisdigit': False, 'word.nextword': 'อื่น', 'word.nextisspace': False, 'word.nextpostag': 'DET', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'อื่น', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'DET', 'word.isdigit()': False, 'word.prevword': 'บริษัท', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'เก็บ', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'เก็บ', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': 'อื่น', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'DET', 'word.prevwordisdigit': False, 'word.nextword': 'ไป', 'word.nextisspace': False, 'word.nextpostag': 'AUX', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'ไป', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'AUX', 'word.isdigit()': False, 'word.prevword': 'เก็บ', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'EOS': True}]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.867959652466252\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "        B-DATE      0.902     0.828     0.863       377\n",
      "        I-DATE      0.917     0.944     0.930       832\n",
      "       B-EMAIL      0.667     0.667     0.667         3\n",
      "       I-EMAIL      1.000     0.889     0.941        18\n",
      "         B-LAW      0.708     0.531     0.607        32\n",
      "         I-LAW      0.823     0.718     0.767       110\n",
      "         B-LEN      1.000     1.000     1.000        15\n",
      "         I-LEN      1.000     1.000     1.000        30\n",
      "    B-LOCATION      0.865     0.797     0.830       869\n",
      "    I-LOCATION      0.865     0.758     0.808       843\n",
      "       B-MONEY      0.930     0.898     0.914       118\n",
      "       I-MONEY      0.811     0.938     0.870       306\n",
      "B-ORGANIZATION      0.922     0.792     0.852      1113\n",
      "I-ORGANIZATION      0.852     0.761     0.804      1236\n",
      "     B-PERCENT      0.972     0.921     0.946        38\n",
      "     I-PERCENT      0.966     0.949     0.957        59\n",
      "      B-PERSON      0.931     0.825     0.874       604\n",
      "      I-PERSON      0.908     0.907     0.907      2141\n",
      "       B-PHONE      0.929     0.619     0.743        21\n",
      "       I-PHONE      0.945     0.963     0.954        54\n",
      "        B-TIME      0.831     0.790     0.810       162\n",
      "        I-TIME      0.899     0.854     0.876       343\n",
      "         B-URL      1.000     1.000     1.000        21\n",
      "         I-URL      1.000     1.000     1.000       315\n",
      "         B-ZIP      1.000     0.833     0.909        12\n",
      "\n",
      "     micro avg      0.896     0.844     0.869      9672\n",
      "     macro avg      0.906     0.847     0.873      9672\n",
      "  weighted avg      0.895     0.844     0.868      9672\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_data = [extract_features(doc) for doc in datatofile]\n",
    "y_data = [get_labels(doc) for doc in datatofile]\n",
    "\n",
    "X, X_test, y, y_test = train_test_split(X_data, y_data, test_size=0.2)\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=500,\n",
    "    all_possible_transitions=True,\n",
    "    model_filename=file_name+\"-pos.model0\"\n",
    ")\n",
    "crf.fit(X, y);\n",
    "\n",
    "labels = list(crf.classes_)\n",
    "labels.remove('O')\n",
    "y_pred = crf.predict(X_test)\n",
    "e=metrics.flat_f1_score(y_test, y_pred,\n",
    "                      average='weighted', labels=labels)\n",
    "print(e)\n",
    "sorted_labels = sorted(\n",
    "    labels,\n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del X_data[0]\n",
    "#del y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'word.word': ' ', 'word.stopword': False, 'word.isthai': False, 'word.isspace': True, 'postag': 'PUNCT', 'word.isdigit()': False, 'BOS': True, 'word.nextword': '[', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': '[', 'word.stopword': False, 'word.isthai': False, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': ' ', 'word.previsspace': True, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'PUNCT', 'word.prevwordisdigit': False, 'word.nextword': 'ORGANIZATION', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ORGANIZATION', 'word.stopword': False, 'word.isthai': False, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': '[', 'word.previsspace': False, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': ']', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': ']', 'word.stopword': False, 'word.isthai': False, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'ORGANIZATION', 'word.previsspace': False, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ไมโครซอฟท์', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ไมโครซอฟท์', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': ']', 'word.previsspace': False, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ทดสอบ', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ทดสอบ', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': 'ไมโครซอฟท์', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ฟีเจอร์', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ฟีเจอร์', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'ทดสอบ', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'word.nextword': 'ใหม่', 'word.nextisspace': False, 'word.nextpostag': 'ADJ', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'ใหม่', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'ADJ', 'word.isdigit()': False, 'word.prevword': 'ฟีเจอร์', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': ' ', 'word.nextisspace': True, 'word.nextpostag': 'PUNCT', 'word.nextisthai': False, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': ' ', 'word.stopword': False, 'word.isthai': False, 'word.isspace': True, 'postag': 'PUNCT', 'word.isdigit()': False, 'word.prevword': 'ใหม่', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'ADJ', 'word.prevwordisdigit': False, 'word.nextword': 'เป็น', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'เป็น', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': ' ', 'word.previsspace': True, 'word.previsthai': False, 'word.prevstopword': False, 'word.prepostag': 'PUNCT', 'word.prevwordisdigit': False, 'word.nextword': 'ช่องทาง', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ช่องทาง', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'เป็น', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'word.nextword': 'จัดการ', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'จัดการ', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': 'ช่องทาง', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ข้อมูล', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ข้อมูล', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'จัดการ', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'word.nextword': 'ส่วนตัว', 'word.nextisspace': False, 'word.nextpostag': 'ADJ', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'ส่วนตัว', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'ADJ', 'word.isdigit()': False, 'word.prevword': 'ข้อมูล', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'ที่', 'word.nextisspace': False, 'word.nextpostag': 'SCONJ', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'ที่', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'SCONJ', 'word.isdigit()': False, 'word.prevword': 'ส่วนตัว', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'ADJ', 'word.prevwordisdigit': False, 'word.nextword': 'บริษัท', 'word.nextisspace': False, 'word.nextpostag': 'NOUN', 'word.nextisthai': True, 'word.nextstopword': False, 'word.nextwordisdigit': False}, {'word.word': 'บริษัท', 'word.stopword': False, 'word.isthai': True, 'word.isspace': False, 'postag': 'NOUN', 'word.isdigit()': False, 'word.prevword': 'ที่', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'SCONJ', 'word.prevwordisdigit': False, 'word.nextword': 'อื่น', 'word.nextisspace': False, 'word.nextpostag': 'DET', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'อื่น', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'DET', 'word.isdigit()': False, 'word.prevword': 'บริษัท', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': False, 'word.prepostag': 'NOUN', 'word.prevwordisdigit': False, 'word.nextword': 'เก็บ', 'word.nextisspace': False, 'word.nextpostag': 'VERB', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'เก็บ', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'VERB', 'word.isdigit()': False, 'word.prevword': 'อื่น', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'DET', 'word.prevwordisdigit': False, 'word.nextword': 'ไป', 'word.nextisspace': False, 'word.nextpostag': 'AUX', 'word.nextisthai': True, 'word.nextstopword': True, 'word.nextwordisdigit': False}, {'word.word': 'ไป', 'word.stopword': True, 'word.isthai': True, 'word.isspace': False, 'postag': 'AUX', 'word.isdigit()': False, 'word.prevword': 'เก็บ', 'word.previsspace': False, 'word.previsthai': True, 'word.prevstopword': True, 'word.prepostag': 'VERB', 'word.prevwordisdigit': False, 'EOS': True}]\n"
     ]
    }
   ],
   "source": [
    "crf2 = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=500,\n",
    "    all_possible_transitions=True,\n",
    "    model_filename=file_name+\".model\"\n",
    ")\n",
    "crf2.fit(X_data, y_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "with open(\"datatrain.data\", \"wb\") as dill_file:\n",
    " dill.dump(datatofile, dill_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport dill\\nwith open(\"datatrain.data\", \"wb\") as dill_file:\\n dill.dump(datatofile, dill_file)\\nf1_scorer = make_scorer(metrics.flat_f1_score, average=\\'macro\\') \\n\\nscores = cross_validate(crf, X, y, scoring=f1_scorer, cv=5)\\n# save data\\nprint(scores)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cross_validate\n",
    "\"\"\"\n",
    "import dill\n",
    "with open(\"datatrain.data\", \"wb\") as dill_file:\n",
    " dill.dump(datatofile, dill_file)\n",
    "f1_scorer = make_scorer(metrics.flat_f1_score, average='macro') \n",
    "\n",
    "scores = cross_validate(crf, X, y, scoring=f1_scorer, cv=5)\n",
    "# save data\n",
    "print(scores)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
